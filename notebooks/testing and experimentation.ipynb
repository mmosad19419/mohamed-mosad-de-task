{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9c45f0-aa79-4c14-9b43-53be2bb78d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m695.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366c90bc-6c88-45aa-bbe2-9e189eb2797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e37dcea-52eb-450c-a639-6e0fc65b5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the configration file\n",
    "def parse_configs(config_file_path):\n",
    "    \"\"\"\n",
    "    Parses the configuration file and retrieves API credentials.\n",
    "\n",
    "    Args:\n",
    "        config_file_path (str): Path to the configuration file (JSON format).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the API key, API secret, and API endpoint.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(config_file_path) as config_file:\n",
    "        configs = json.load(config_file)\n",
    "\n",
    "    # retrieve API credientials\n",
    "    NYT_BOOKS_API_KEY = configs[\"API\"][\"NYT_BOOKS_API_KEY\"]\n",
    "    NYT_BOOKS_API_SECRET = configs[\"API\"][\"NYT_BOOKS_API_SECRET\"]\n",
    "    NYT_BOOKS_API_ENDPOINT = configs[\"API\"][\"NYT_API_ENDPOINT\"]\n",
    "\n",
    "    return NYT_BOOKS_API_KEY, NYT_BOOKS_API_SECRET, NYT_BOOKS_API_ENDPOINT\n",
    "\n",
    "\n",
    "def generate_incremental_dates(start_date, end_date, offset):\n",
    "    \"\"\"\n",
    "    Generates a list of dates starting from `start_date`, incremented by `offset`, \n",
    "    until the `end_date` is reached.\n",
    "\n",
    "    Args:\n",
    "        start_date (str): The starting date in the format \"YYYY-MM-DD\".\n",
    "        end_date (str): The ending date in the format \"YYYY-MM-DD\".\n",
    "        offset (int): The number of days to increment for each date in the range.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of `datetime` objects representing the dates from `start_date`\n",
    "              to `end_date`, incremented by `offset` days.\n",
    "    \"\"\"\n",
    "\n",
    "    # format dates\n",
    "    start_date = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    # init date variable\n",
    "    date = start_date\n",
    "\n",
    "    # Init dates list\n",
    "    dates = []\n",
    "\n",
    "    # loop to get all required dates in specified range\n",
    "    while date <= end_date:\n",
    "        dates.append(date)\n",
    "\n",
    "        date += timedelta(days=offset)\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "# Define a function to fetch data from API\n",
    "def fetch_data_from_api(NYT_BOOKS_API_KEY, DATE):\n",
    "    \"\"\"\n",
    "    Fetches book data from the New York Times Books API for a specific date and \n",
    "    saves the response as a JSON file in the `raw_data` folder.\n",
    "\n",
    "    Args:\n",
    "        NYT_BOOKS_API_KEY (str): The API key for accessing the New York Times Books API.\n",
    "        DATE (str): The date for which to fetch book data, in the format \"YYYY-MM-DD\".\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value. It saves the data to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    # connect to API and pull data\n",
    "    URL = f\"https://api.nytimes.com/svc/books/v3/lists/overview.json?published_date={DATE}&api-key={NYT_BOOKS_API_KEY}\"\n",
    "    response = requests.get(URL)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Save the data to a JSON file in the raw_data folder\n",
    "        os.makedirs(\"./raw_data\", exist_ok=True)\n",
    "\n",
    "        with open(f\"./raw_data/{DATE}.json\", \"w\") as raw_file:\n",
    "            json.dump(response.json(), raw_file)\n",
    "    else:\n",
    "        raise Exception(f\"Failed to fetch data from API. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d29548e-a1a0-4184-8331-711b271292d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uXunYAlGg7Bp446vfkb2dU2iMCTGvZXo 2f6wNv3eXA3GYWM9 https://api.nytimes.com/svc/books/v3/lists/overview.json\n"
     ]
    }
   ],
   "source": [
    "# get API credientials\n",
    "NYT_BOOKS_API_KEY, NYT_BOOKS_API_SECRET, NYT_BOOKS_API_ENDPOINT = parse_configs('../config.json')\n",
    "\n",
    "print(NYT_BOOKS_API_KEY, NYT_BOOKS_API_SECRET, NYT_BOOKS_API_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5c5427-2342-4435-b1a6-7ec1efb54304",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-12-27'\n",
    "END_DATE = '2023-12-31'\n",
    "OFFSET = 7\n",
    "\n",
    "dates = generate_incremental_dates(START_DATE, END_DATE, OFFSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd553ac-7c24-4f1c-8afe-6a3200e5c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for date in dates:\n",
    "#     fetch_data_from_api(NYT_BOOKS_API_KEY, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41624426-9bde-4951-9db0-8f477c60789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the transformed data into the DWH\n",
    "def init_db_connection(host, database, user, password, port):\n",
    "    # Connect to PostgreSQL (replace with your own connection details)\n",
    "    conn = psycopg2.connect(\n",
    "        host=host,\n",
    "        dbname=database,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        port=port\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    return conn, cursor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141ae337-1d9e-486b-a70c-9b204a44654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn, cursor = init_db_connection(\"postgres-dev\", \"mydb\", \"admin\", \"admin\", \"5432\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "330c463e-9b1d-4264-83a9-19eb017db484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "WITH RECURSIVE date_series AS (\n",
    "    SELECT '2010-01-01'::DATE AS Date\n",
    "    UNION ALL\n",
    "    SELECT (Date + INTERVAL '1 day')::DATE as Date\n",
    "    FROM date_series\n",
    "    WHERE Date < '2030-12-31'\n",
    ")\n",
    "INSERT INTO dwh.DimDate\n",
    "    (\n",
    "        DateKey,\n",
    "        FullDate,\n",
    "        DayOfMonth,\n",
    "        DayName,\n",
    "        DayOfWeek,\n",
    "        DayOfYear,\n",
    "        WeekOfYear,\n",
    "        Month,\n",
    "        MonthName,\n",
    "        Quarter,\n",
    "        Year,\n",
    "        MonthYear\n",
    "    )\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM Date) * 10000 + EXTRACT(MONTH FROM Date) * 100 + EXTRACT(DAY FROM Date) AS DateKey,\n",
    "    Date AS FullDate,\n",
    "    TO_CHAR(Date, 'DD') AS DayOfMonth,\n",
    "    TO_CHAR(Date, 'FMDay') AS DayName,\n",
    "    EXTRACT(DOW FROM Date) + 1 AS DayOfWeek,  -- Day of the week starting from Sunday = 1\n",
    "    EXTRACT(DOY FROM Date) AS DayOfYear,\n",
    "    TO_CHAR(Date, 'IW') AS WeekOfYear,\n",
    "    TO_CHAR(Date, 'MM') AS Month,\n",
    "    TO_CHAR(Date, 'FMMonth') AS MonthName,\n",
    "    CASE \n",
    "        WHEN EXTRACT(MONTH FROM Date) BETWEEN 1 AND 3 THEN '1'\n",
    "        WHEN EXTRACT(MONTH FROM Date) BETWEEN 4 AND 6 THEN '2'\n",
    "        WHEN EXTRACT(MONTH FROM Date) BETWEEN 7 AND 9 THEN '3'\n",
    "        WHEN EXTRACT(MONTH FROM Date) BETWEEN 10 AND 12 THEN '4'\n",
    "    END AS Quarter,\n",
    "    TO_CHAR(Date, 'YYYY') AS Year,\n",
    "    TO_CHAR(Date, 'YYYYMM') AS MonthYear\n",
    "FROM date_series\n",
    ";\n",
    "\n",
    "           \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3f118df-6bcf-4ccd-90ec-6d21fb2ac600",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"CREATE TABLE dwh.DimDate (\n",
    "  DateKey integer,\n",
    "  FullDate date PRIMARY KEY,\n",
    "  DayOfMonth varchar,\n",
    "  DayName varchar,\n",
    "  DayOfWeek varchar,\n",
    "  DayOfYear varchar,\n",
    "  WeekOfYear varchar,\n",
    "  Month varchar,\n",
    "  MonthName varchar,\n",
    "  Quarter varchar,\n",
    "  Year varchar,\n",
    "  MonthYear varchar\n",
    ");\n",
    "           \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90a64db2-fd82-4a34-b00b-79b72fb75f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42e16b33-e9a3-484f-b84f-69955a46dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a016248-a2d3-48fc-8829-83054d1ca9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<psycopg.Cursor [COMMAND_OK] [INTRANS] (host=postgres-dev user=admin database=mydb) at 0xffff901deeb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\n",
    "            \"INSERT INTO test (num, data) VALUES (%s, %s)\",\n",
    "            (100, \"abc'def\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "411d0b81-bb13-47c6-8339-e3463a422306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execute(\"SELECT * FROM dwh.DimDate\")\n",
    "# cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c314443a-1d88-47ed-8d1e-1c07d8a44ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for record in cursor:\n",
    "#     print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8272293f-7ad4-46cb-9db6-300a8af19529",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"stage.lists\" does not exist\nLINE 2:         INSERT INTO stage.lists (id, list_name, list_name_en...\n                            ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# print(data)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m df_lists, df_books, df_buy_links, df_best_sellers \u001b[38;5;241m=\u001b[39m transform_data(data)\n\u001b[0;32m--> 121\u001b[0m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_books\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_buy_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_best_sellers\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [15], line 84\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(cursor, df_lists, df_books, df_buy_links, df_best_sellers)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(cursor, df_lists, df_books, df_buy_links, df_best_sellers):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Insert data into DimLists\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mexecute_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;43m        INSERT INTO stage.lists (id, list_name, list_name_encoded, display_name, updated, list_image, list_image_width, list_image_height)\u001b[39;49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;43m        VALUES (\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_lists\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Insert data into DimBooks\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     execute_batch(cursor, \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124m        INSERT INTO stage.books (id, title, publisher, author, contributor, contributor_note, description, created_date, updated_date, age_group, amazon_product_url, primary_isbn13, primary_isbn10, book_image_width, book_image_height, first_chapter_link, book_uri, sunday_review_link)\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124m        VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, df_books\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/psycopg2/extras.py:1216\u001b[0m, in \u001b[0;36mexecute_batch\u001b[0;34m(cur, sql, argslist, page_size)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m _paginate(argslist, page_size\u001b[38;5;241m=\u001b[39mpage_size):\n\u001b[1;32m   1215\u001b[0m     sqls \u001b[38;5;241m=\u001b[39m [cur\u001b[38;5;241m.\u001b[39mmogrify(sql, args) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m page]\n\u001b[0;32m-> 1216\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mUndefinedTable\u001b[0m: relation \"stage.lists\" does not exist\nLINE 2:         INSERT INTO stage.lists (id, list_name, list_name_en...\n                            ^\n"
     ]
    }
   ],
   "source": [
    "def transform_data(data):\n",
    "    # init lists to store each table data\n",
    "    lists_data = []\n",
    "    books_data = []\n",
    "    buy_links_data = []\n",
    "    fact_best_sellers_data = []\n",
    "    date_data = []\n",
    "\n",
    "    # DimLists\n",
    "    for list_entry in data['results']['lists']:\n",
    "        list_dict = {\n",
    "            'id': list_entry['list_id'],\n",
    "            'list_name': list_entry['list_name'],\n",
    "            'list_name_encoded': list_entry['list_name_encoded'],\n",
    "            'display_name': list_entry['display_name'],\n",
    "            'updated': datetime.strptime(data['results']['bestsellers_date'], \"%Y-%m-%d\").date(),\n",
    "            'list_image': list_entry.get('list_image', ''),\n",
    "            'list_image_width': list_entry.get('list_image_width', None),\n",
    "            'list_image_height': list_entry.get('list_image_height', None),\n",
    "        }\n",
    "        lists_data.append(list_dict)\n",
    "\n",
    "        # DimBooks\n",
    "        for book in list_entry['books']:\n",
    "            book_id = book['primary_isbn13']\n",
    "            book_dict = {\n",
    "                'id': book_id,\n",
    "                'title': book['title'],\n",
    "                'publisher': book['publisher'],\n",
    "                'author': book['author'],\n",
    "                'contributor': book['contributor'],\n",
    "                'contributor_note': book['contributor_note'],\n",
    "                'description': book['description'],\n",
    "                'created_date': datetime.strptime(book['created_date'], \"%Y-%m-%d %H:%M:%S\").date(),\n",
    "                'updated_date': datetime.strptime(book['updated_date'], \"%Y-%m-%d %H:%M:%S\").date(),\n",
    "                'age_group': book['age_group'],\n",
    "                'amazon_product_url': book['amazon_product_url'],\n",
    "                'primary_isbn13': book['primary_isbn13'],\n",
    "                'primary_isbn10': book['primary_isbn10'],\n",
    "                'book_image_width': book['book_image_width'],\n",
    "                'book_image_height': book['book_image_height'],\n",
    "                'first_chapter_link': book['first_chapter_link'],\n",
    "                'book_uri': book['book_uri'],\n",
    "                'sunday_review_link': book['sunday_review_link']\n",
    "            }\n",
    "            books_data.append(book_dict)\n",
    "\n",
    "            # DimBooksBuyLinks\n",
    "            for buy_link in book['buy_links']:\n",
    "                buy_link_dict = {\n",
    "                    'book_id': book_id,\n",
    "                    'website_name': buy_link['name'],\n",
    "                    'website_url': buy_link['url']\n",
    "                }\n",
    "                buy_links_data.append(buy_link_dict)\n",
    "\n",
    "            # Fct_best_sellers_publish\n",
    "            fct_best_seller_dict = {\n",
    "                'bestsellers_date': datetime.strptime(data['results']['bestsellers_date'], \"%Y-%m-%d\").date(),\n",
    "                'published_date': datetime.strptime(data['results']['published_date'], \"%Y-%m-%d\").date(),\n",
    "                'previous_published_date': datetime.strptime(data['results']['previous_published_date'], \"%Y-%m-%d\").date(),\n",
    "                'next_published_date': datetime.strptime(data['results']['next_published_date'], \"%Y-%m-%d\").date(),\n",
    "                'list_id': list_entry['list_id'],\n",
    "                'book_id': book_id,\n",
    "                'rank': book['rank'],\n",
    "                'weeks_on_list': book['weeks_on_list'],\n",
    "                'price': book['price']\n",
    "            }\n",
    "            fact_best_sellers_data.append(fct_best_seller_dict)\n",
    "\n",
    "\n",
    "    # Convert to DataFrames\n",
    "    df_lists = pd.DataFrame(lists_data)\n",
    "    df_books = pd.DataFrame(books_data)\n",
    "    df_buy_links = pd.DataFrame(buy_links_data)\n",
    "    df_best_sellers = pd.DataFrame(fact_best_sellers_data)\n",
    "\n",
    "    return df_lists, df_books, df_buy_links, df_best_sellers\n",
    "\n",
    "\n",
    "# Function to load the transformed data into the DWH\n",
    "def load_data(cursor, df_lists, df_books, df_buy_links, df_best_sellers):\n",
    "    # Insert data into DimLists\n",
    "    execute_batch(cursor, \"\"\"\n",
    "        INSERT INTO stage.lists (id, list_name, list_name_encoded, display_name, updated, list_image, list_image_width, list_image_height)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", df_lists.values.tolist())\n",
    "\n",
    "    # Insert data into DimBooks\n",
    "    execute_batch(cursor, \"\"\"\n",
    "        INSERT INTO stage.books (id, title, publisher, author, contributor, contributor_note, description, created_date, updated_date, age_group, amazon_product_url, primary_isbn13, primary_isbn10, book_image_width, book_image_height, first_chapter_link, book_uri, sunday_review_link)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", df_books.values.tolist())\n",
    "\n",
    "    # Insert data into DimBooksBuyLinks\n",
    "    execute_batch(cursor, \"\"\"\n",
    "        INSERT INTO stage.books_buy_links (book_id, website_name, website_url)\n",
    "        VALUES (%s, %s, %s)\n",
    "    \"\"\", df_buy_links.values.tolist())\n",
    "\n",
    "    # Insert data into Fct_best_sellers_publish\n",
    "    execute_batch(cursor, \"\"\"\n",
    "        INSERT INTO stage.best_sellers_puplish (bestsellers_date, published_date, previous_published_date, next_published_date, list_id, book_id, rank, weeks_on_list, price)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", df_best_sellers.values.tolist())\n",
    "\n",
    "    # Commit and close\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('../raw_data/2021-01-03.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "# print(data)\n",
    "\n",
    "df_lists, df_books, df_buy_links, df_best_sellers = transform_data(data)\n",
    "load_data(cursor, df_lists, df_books, df_buy_links, df_best_sellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "777f93a1-edd6-452e-982c-3b028176c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64d330-8f34-4d09-a6ea-b9e9b77821e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
